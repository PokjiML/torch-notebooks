{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset                     # For training\n",
        "from torch.optim.lr_scheduler import LambdaLR, StepLR   # For warmup and LR scheduling\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "KlczoKnu1asu"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Image Augmentation\n",
        "aug_transform = transforms.Compose([\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.01, 0.01)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "org_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "# Declare the original\n",
        "aug_train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=aug_transform)\n",
        "org_train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=org_transform)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=False, transform = org_transform)\n",
        "\n",
        "# Concatenate both datasets\n",
        "concat_dataset = ConcatDataset([aug_train_dataset, org_train_dataset])\n",
        "\n",
        "train_loader = DataLoader(concat_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "B28E319y3e_o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5e6c955-936b-48c7-d313-9df40de89da8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 49.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce the datasets for development\n",
        "subset_train_dataset = Subset(concat_dataset, list(range(10000)))\n",
        "subset_test_dataset = Subset(test_dataset, list(range(2000)))\n",
        "\n",
        "# Data loader declaration\n",
        "subset_train_loader = DataLoader(subset_train_dataset, batch_size=128, shuffle=True)\n",
        "subset_test_loader = DataLoader(subset_test_dataset, batch_size=128, shuffle=True)\n",
        "\n",
        "len(subset_train_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k095V65PYRig",
        "outputId": "ab01590b-dad3-4ee7-cb5e-593caef97794"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example = next(iter(train_loader))\n",
        "\n",
        "example = (example[0][0] + 1) / 2 # normalize back to [0, 1] from [-1, 1]\n",
        "plt.imshow(example.numpy().transpose(1, 2, 0))\n",
        "plt.axis('off')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "58u-qMK_1nCl",
        "outputId": "d56a430f-c839-4ce3-bb4e-995fa1169e0e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.5, 31.5, 31.5, -0.5)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        #Conv layer                                                       # in (batch, in_channels, img_h, img_w)\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3,  # -> (batch, out_channels, img_h, img_w)\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        # Batch normalization\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        # Nonlinearity\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        # Second Convolution layer\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, # -> (batch, out_channels, img_h, img_w)\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        # Batch normalization\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        # Residual connection (do nothing if dimensions match)\n",
        "        self.downsample = nn.Sequential()\n",
        "        if in_channels != out_channels:\n",
        "            self.downsample = nn.Sequential(\n",
        "            #   Change the dim with 1x1 convolution                             # (batch_ in_channel, img_h, img_w)\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False) # -> (batch, out_channel, img_h, img_w)\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Save the residual connection\n",
        "        identity = x\n",
        "        # Convolution -> Batch_norm -> ReLU\n",
        "        x = self.relu(self.bn1(self.conv1(x))) # -> (batch, out_channel, img_h, img_w)\n",
        "        x = self.relu(self.bn2(self.conv2(x))) # -> (batch, out_channel, img_h, img_w)\n",
        "        x += self.downsample(identity) # add residual connection\n",
        "        x += self.relu(x)\n",
        "        return(x)\n",
        "\n"
      ],
      "metadata": {
        "id": "XAVeRx1kiI25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ResidualCNN, self).__init__()\n",
        "\n",
        "        # Initial conv layer\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        self.res_layer1 = nn.Sequential(\n",
        "            ResidualBlock(16, 16),\n",
        "            ResidualBlock(16, 16),\n",
        "            ResidualBlock(16, 16)\n",
        "        )\n"
      ],
      "metadata": {
        "id": "Ydg_ra24nucf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1) # (4, 3, 32, 32) -> (4, 16, 32, 32)\n",
        "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1) # -> (4, 32, 32, 32)\n",
        "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1) # -> (4, 64, 16, 16)\n",
        "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(in_features=128*8*8, out_features=128) # -> (4, 128)\n",
        "        self.fc2 = nn.Linear(in_features=128, out_features=10) # -> (4, 10)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.res_conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=1, stride=1, padding=0)\n",
        "        self.res_conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=1, stride=2, padding=0) # (4, 32, y/2, x/2)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x # (4, 3, 32, 32)\n",
        "        x = self.relu(self.conv1(x)) # -> (4, 16, 32, 32)\n",
        "        x = x + self.res_conv1(identity) # residual connection\n",
        "        identity = x # (4, 16, 32, 32)\n",
        "        x = self.bn1(self.relu(self.conv2(x))) # -> (4, 32, 32, 32)\n",
        "        x = self.pool(x) # -> (4, 32, 16, 16)\n",
        "        x = x + self.res_conv2(identity) # residual_connection\n",
        "        x = self.bn2(self.relu(self.conv3(x))) # -> (4, 64, 16, 16)\n",
        "        x = self.pool(x) # -> (4, 64, 8, 8)\n",
        "        x = self.bn3(self.relu(self.conv4(x))) # -> (4, 128, 8, 8) x\n",
        "        x = x.view(-1, 128*8*8) # -> (4, 64*8*8)\n",
        "        x = self.relu(self.fc1(x)) # -> (4, 128)\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc2(x)) # -> (4, 10)\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "OjmESqSJV369"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = CNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "T_WXY71jPS9G"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def warmup_lambda(epoch):\n",
        "    warmup_epochs = 5\n",
        "    if epoch < warmup_epochs:\n",
        "        return (epoch + 1) / warmup_epochs # Linearly scale warmup\n",
        "    else:\n",
        "        return 1.0\n",
        "\n",
        "# warmup = lambda epoch: (epoch + 1) / 5\n",
        "\n",
        "# Warmup scheduler\n",
        "warmup_scheduler = LambdaLR(optimizer, lr_lambda=warmup_lambda)\n",
        "\n",
        "# Main scheduler\n",
        "main_scheduler = StepLR(optimizer, step_size=5, gamma = 0.1)\n"
      ],
      "metadata": {
        "id": "APdUXIMg5Q9N"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 20\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # forward pass\n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "\n",
        "        # backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Track loss\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    if epoch < 5:\n",
        "        warmup_scheduler.step()\n",
        "    else:\n",
        "        main_scheduler.step()\n",
        "\n",
        "    avg_loss = running_loss / len(subset_train_loader)\n",
        "    print(f\"Epoch [{epoch}], Loss: {avg_loss:.4f}, LR: {main_scheduler.get_last_lr()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fx_BtdnLQr0r",
        "outputId": "50e8bcaa-5b45-4142-cf34-b419f4a6cdd6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0], Loss: 21.9070, LR: [0.0002]\n",
            "Epoch [1], Loss: 15.4532, LR: [0.0002]\n",
            "Epoch [2], Loss: 12.8795, LR: [0.0002]\n",
            "Epoch [3], Loss: 11.3997, LR: [0.0002]\n",
            "Epoch [4], Loss: 10.3678, LR: [0.0002]\n",
            "Epoch [5], Loss: 8.9143, LR: [0.001]\n",
            "Epoch [6], Loss: 7.7597, LR: [0.001]\n",
            "Epoch [7], Loss: 6.9668, LR: [0.001]\n",
            "Epoch [8], Loss: 6.3478, LR: [0.001]\n",
            "Epoch [9], Loss: 5.9199, LR: [0.0001]\n",
            "Epoch [10], Loss: 4.1964, LR: [0.0001]\n",
            "Epoch [11], Loss: 3.5979, LR: [0.0001]\n",
            "Epoch [12], Loss: 3.2934, LR: [0.0001]\n",
            "Epoch [13], Loss: 3.1534, LR: [0.0001]\n",
            "Epoch [14], Loss: 2.9416, LR: [1e-05]\n",
            "Epoch [15], Loss: 2.7867, LR: [1e-05]\n",
            "Epoch [16], Loss: 2.7216, LR: [1e-05]\n",
            "Epoch [17], Loss: 2.7215, LR: [1e-05]\n",
            "Epoch [18], Loss: 2.7031, LR: [1e-05]\n",
            "Epoch [19], Loss: 2.6631, LR: [1.0000000000000002e-06]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = correct / len(test_dataset)\n",
        "print(f'The accuracy of the model is {accuracy}')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnMnENilSHa6",
        "outputId": "9e9377c4-d592-4a97-c49c-077c704afd3a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy of the model is 0.8416\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qi2wCzbPfloC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}