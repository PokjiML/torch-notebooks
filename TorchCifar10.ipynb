{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset                     # For training\n",
        "from torch.optim.lr_scheduler import LambdaLR, StepLR   # For warmup and LR scheduling\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "KlczoKnu1asu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Image Augmentation\n",
        "aug_transform = transforms.Compose([\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.01, 0.01)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "org_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "# Declare the original\n",
        "aug_train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=aug_transform)\n",
        "org_train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=org_transform)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=False, transform = org_transform)\n",
        "\n",
        "# Concatenate both datasets\n",
        "concat_dataset = ConcatDataset([aug_train_dataset, org_train_dataset])\n",
        "\n",
        "train_loader = DataLoader(concat_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "B28E319y3e_o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3be95208-fb49-4484-8d8c-73b7ed288bc8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce the datasets for development\n",
        "subset_train_dataset = Subset(concat_dataset, list(range(10000)))\n",
        "subset_test_dataset = Subset(test_dataset, list(range(2000)))\n",
        "\n",
        "# Data loader declaration\n",
        "subset_train_loader = DataLoader(subset_train_dataset, batch_size=128, shuffle=True)\n",
        "subset_test_loader = DataLoader(subset_test_dataset, batch_size=128, shuffle=True)\n",
        "\n",
        "len(subset_train_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k095V65PYRig",
        "outputId": "02d1813b-f1a9-4daf-eddf-cacc99bbd9fb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example = next(iter(train_loader))\n",
        "\n",
        "example = (example[0][0] + 1) / 2 # normalize back to [0, 1] from [-1, 1]\n",
        "plt.imshow(example.numpy().transpose(1, 2, 0))\n",
        "plt.axis('off')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "58u-qMK_1nCl",
        "outputId": "293f3326-3080-409e-9ed6-05c9858daf78"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.5, 31.5, 31.5, -0.5)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        #Conv layer                                                       # in (batch, in_channels, img_h, img_w)\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3,  # -> (batch, out_channels, img_h, img_w)\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        # Batch normalization\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        # Nonlinearity\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        # Second Convolution layer\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, # -> (batch, out_channels, img_h, img_w)\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        # Batch normalization\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        # Residual connection (do nothing if dimensions match)\n",
        "        self.downsample = nn.Sequential()\n",
        "        if in_channels != out_channels:\n",
        "            self.downsample = nn.Sequential(\n",
        "            #   Change the dim with 1x1 convolution                             # (batch_ in_channel, img_h, img_w)\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False) # -> (batch, out_channel, img_h, img_w)\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Save the residual connection\n",
        "        identity = x\n",
        "        # Convolution -> Batch_norm -> ReLU\n",
        "        x = self.relu(self.bn1(self.conv1(x))) # -> (batch, out_channel, img_h, img_w)\n",
        "        x = self.relu(self.bn2(self.conv2(x))) # -> (batch, out_channel, img_h, img_w)\n",
        "        x += self.downsample(identity) # add residual connection\n",
        "        x += self.relu(x)\n",
        "        return(x)\n",
        "\n"
      ],
      "metadata": {
        "id": "XAVeRx1kiI25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ResidualCNN, self).__init__()\n",
        "\n",
        "        # Initial conv layer\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        self.res_layer1 = nn.Sequential(\n",
        "            ResidualBlock(16, 16),\n",
        "            ResidualBlock(16, 16),\n",
        "            ResidualBlock(16, 16)\n",
        "        )\n"
      ],
      "metadata": {
        "id": "Ydg_ra24nucf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1) # (4, 3, 32, 32) -> (4, 16, 32, 32)\n",
        "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1) # -> (4, 32, 32, 32)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2) # -> (4, 32, 16, 16)\n",
        "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1) # -> (4, 64, 16, 16)\n",
        "        self.fc1 = nn.Linear(in_features=64*8*8, out_features=128) # -> (4, 128)\n",
        "        self.fc2 = nn.Linear(in_features=128, out_features=10) # -> (4, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.res_conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=1, stride=1, padding=0)\n",
        "        self.res_conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x # (4, 3, 32, 32)\n",
        "        x = self.relu(self.conv1(x)) # -> (4, 16, 32, 32)\n",
        "        x = x + self.res_conv1(identity) # residual connection\n",
        "        x = self.bn1(self.relu(self.conv2(x))) # -> (4, 32, 32, 32)\n",
        "        x = self.pool(x) # -> (4, 32, 16, 16)\n",
        "        x = self.bn2(self.relu(self.conv3(x))) # -> (4, 64, 16, 16)\n",
        "        x = self.pool(x) # -> (4, 64, 8, 8)\n",
        "        x = x.view(-1, 64*8*8) # -> (4, 64*8*8)\n",
        "        x = self.relu(self.fc1(x)) # -> (4, 128)\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc2(x)) # -> (4, 10)\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "OjmESqSJV369"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = CNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "T_WXY71jPS9G"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def warmup_lambda(epoch):\n",
        "    warmup_epochs = 5\n",
        "    if epoch < warmup_epochs:\n",
        "        return (epoch + 1) / warmup_epochs # Linearly scale warmup\n",
        "    else:\n",
        "        return 1.0\n",
        "\n",
        "# warmup = lambda epoch: (epoch + 1) / 5\n",
        "\n",
        "# Warmup scheduler\n",
        "warmup_scheduler = LambdaLR(optimizer, lr_lambda=warmup_lambda)\n",
        "\n",
        "# Main scheduler\n",
        "main_scheduler = StepLR(optimizer, step_size=10, gamma = 0.1)\n"
      ],
      "metadata": {
        "id": "APdUXIMg5Q9N"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 20\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in subset_train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # forward pass\n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "\n",
        "        # backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Track loss\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    if epoch < 5:\n",
        "        warmup_scheduler.step()\n",
        "    else:\n",
        "        main_scheduler.step()\n",
        "\n",
        "    avg_loss = running_loss / len(subset_train_loader)\n",
        "    print(f\"Epoch [{epoch}], Loss: {avg_loss:.4f}, LR: {main_scheduler.get_last_lr()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fx_BtdnLQr0r",
        "outputId": "f37a6134-fb3f-4a06-9c8f-7ab4436b2cab"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0], Loss: 1.7640, LR: [0.0002]\n",
            "Epoch [1], Loss: 1.4500, LR: [0.0002]\n",
            "Epoch [2], Loss: 1.3165, LR: [0.0002]\n",
            "Epoch [3], Loss: 1.2257, LR: [0.0002]\n",
            "Epoch [4], Loss: 1.1517, LR: [0.0002]\n",
            "Epoch [5], Loss: 1.0851, LR: [0.001]\n",
            "Epoch [6], Loss: 0.9902, LR: [0.001]\n",
            "Epoch [7], Loss: 0.9184, LR: [0.001]\n",
            "Epoch [8], Loss: 0.8592, LR: [0.001]\n",
            "Epoch [9], Loss: 0.7972, LR: [0.001]\n",
            "Epoch [10], Loss: 0.7455, LR: [0.001]\n",
            "Epoch [11], Loss: 0.7111, LR: [0.001]\n",
            "Epoch [12], Loss: 0.6650, LR: [0.001]\n",
            "Epoch [13], Loss: 0.6291, LR: [0.001]\n",
            "Epoch [14], Loss: 0.6115, LR: [0.0001]\n",
            "Epoch [15], Loss: 0.5034, LR: [0.0001]\n",
            "Epoch [16], Loss: 0.4592, LR: [0.0001]\n",
            "Epoch [17], Loss: 0.4575, LR: [0.0001]\n",
            "Epoch [18], Loss: 0.4259, LR: [0.0001]\n",
            "Epoch [19], Loss: 0.4260, LR: [0.0001]\n",
            "Epoch [20], Loss: 0.4128, LR: [0.0001]\n",
            "Epoch [21], Loss: 0.4091, LR: [0.0001]\n",
            "Epoch [22], Loss: 0.4048, LR: [0.0001]\n",
            "Epoch [23], Loss: 0.3920, LR: [0.0001]\n",
            "Epoch [24], Loss: 0.3877, LR: [1e-05]\n",
            "Epoch [25], Loss: 0.3703, LR: [1e-05]\n",
            "Epoch [26], Loss: 0.3669, LR: [1e-05]\n",
            "Epoch [27], Loss: 0.3615, LR: [1e-05]\n",
            "Epoch [28], Loss: 0.3610, LR: [1e-05]\n",
            "Epoch [29], Loss: 0.3599, LR: [1e-05]\n",
            "Epoch [30], Loss: 0.3674, LR: [1e-05]\n",
            "Epoch [31], Loss: 0.3628, LR: [1e-05]\n",
            "Epoch [32], Loss: 0.3560, LR: [1e-05]\n",
            "Epoch [33], Loss: 0.3544, LR: [1e-05]\n",
            "Epoch [34], Loss: 0.3584, LR: [1.0000000000000002e-06]\n",
            "Epoch [35], Loss: 0.3551, LR: [1.0000000000000002e-06]\n",
            "Epoch [36], Loss: 0.3639, LR: [1.0000000000000002e-06]\n",
            "Epoch [37], Loss: 0.3603, LR: [1.0000000000000002e-06]\n",
            "Epoch [38], Loss: 0.3560, LR: [1.0000000000000002e-06]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-69778b3f0d2b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-c6e1e63a0b79>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# -> (4, 32, 32, 32)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# -> (4, 32, 16, 16)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# -> (4, 64, 16, 16)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# -> (4, 64, 8, 8)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# -> (4, 64*8*8)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    547\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             )\n\u001b[0;32m--> 549\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = correct / len(test_dataset)\n",
        "print(f'The accuracy of the model is {accuracy}')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnMnENilSHa6",
        "outputId": "fb150f33-b510-48c7-936e-6308095a7ce7"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy of the model is 0.7117\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qi2wCzbPfloC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}